),by="CED_NAME_2016")
load_geo(nonabs,"CED_2016_AUST_GDA2020")
nonabs
nonabs_layers
ceds_2016_out <- load_geo(nonabs,"commonwealth_electoral_division_2016") %>%
filter(CED_NAME_2016 %in% c("Fenner","Bean","Lingiari")) %>%
st_drop_geometry() %>%
select(CED_CODE_2016,CED_NAME_2016) %>%
left_join(tribble(~ SA3_NAME_2016,~CED_NAME_2016,
"Christmas Island","Lingiari",
"Norfolk Island","Bean",
"Jervis Bay","Fenner",
"Cocos (Keeling) Islands","Lingiari",
"Migratory - Offshore - Shipping (OT)","Migratory - Offshore - Shipping (OT)",
"No usual address (OT)","No usual address (OT)"
),by="CED_NAME_2016")
if(exists("ceds_2016_out")){
base<-base %>%
left_join(ceds_2016_out,by="SA3_NAME_2016")
}else{
library(auspol)
divisions <- list_divisions(filters=list(StateAb=str_to_upper(state_short))) %>%
filter(`2016`) %>%
mutate(CED_NAME_2016=str_to_lower(DivisionNm),
CED_NAME_2016 = str_squish(CED_NAME_2016)) |>
distinct(CED_NAME_2016,DivisionNm)
ind <- load_geo(nonabs, layer="commonwealth_electoral_division_2016") %>%
mutate(CED_NAME_2016=str_to_lower(CED_NAME_2016),
CED_NAME_2016 = str_squish(CED_NAME_2016)) |>
left_join(divisions,by="CED_NAME_2016") |>
filter(!is.na(DivisionNm)) |>
mutate(CED_NAME_2016=DivisionNm,.keep="unused")
full_overlap <- full_coverage(base,
bigger=ind,
base_id="id",
bigger_id="CED_CODE_2016")
overlapped <- full_overlap %>%
distinct(id) %>%
mutate(dummy=TRUE)
base_renmant <- base  %>%
left_join(overlapped,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
if(nrow(base_renmant)>0){
intersects <- intersections(base_renmant,
bigger=ind,
base_id="id",
bigger_id="CED_CODE_2016",
base_empty_label="SA2_NAME_2016",
bigger_empty_label="CED_NAME_2016"
)
intersected <- intersects %>%
distinct(id) %>%
mutate(dummy=TRUE)
non_matched <- base_renmant %>%
left_join(intersected,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
}else{
intersects <- base %>% filter(is.null(id))
non_matched <- base %>% filter(is.null(id))
}
base <- base %>%
left_join(full_overlap |> distinct(),by="id") %>%
filter(!is.na(CED_CODE_2016))
base <- bind_rows(base,intersects,non_matched) %>%
mutate(id=row_number())
sa1_nbr <- c(sa1_nbr,nrow(base))
st_write_parquet(base,base_file)
rm(base_renmant,ind,intersects,full_overlap,overlapped,intersected,non_matched)
}
st_write_parquet(base,base_file)
sa1_nbr <- c(sa1_nbr,nrow(base))
rm(base_renmant,ced2021,intersects,full_overlap,non_matched)
#LGAs ----
ind <- load_geo(nonabs, layer="local_government_area_2016") %>%
filter(STE_NAME_2016==state) %>%
select(-STE_CODE_2016,-STE_NAME_2016)
full_overlap <- full_coverage(base,
bigger=ind,
base_id="id",
bigger_id="LGA_CODE_2016")
overlapped <- full_overlap %>%
distinct(id) %>%
mutate(dummy=TRUE)
base_renmant <- base  %>%
left_join(overlapped,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
if(nrow(base_renmant)>0){
intersects <- intersections(base_renmant,
bigger=ind,
base_id="id",
bigger_id="LGA_CODE_2016",
base_empty_label="SA2_NAME_2016",
bigger_empty_label="LGA_NAME_2016"
)
intersected <- intersects %>%
distinct(id) %>%
mutate(dummy=TRUE)
non_matched <- base_renmant %>%
left_join(intersected,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
}else{
intersects <- base %>% filter(is.null(id))
non_matched <- base %>% filter(is.null(id))
}
base <- base %>%
left_join(full_overlap |> distinct(),by="id") %>%
filter(!is.na(LGA_CODE_2016))
base <- bind_rows(base,intersects,non_matched) %>%
mutate(id=row_number())
sa1_nbr <- c(sa1_nbr,nrow(base))
st_write_parquet(base,base_file)
rm(base_renmant,ind,intersects,full_overlap,overlapped,intersected,non_matched)
#POAS ----
library(auscensus)
ind <- load_geo(nonabs, layer="post_code_area_2016") %>%
filter(POA_CODE_2016 %in% as.character(poas_state))
full_overlap <- full_coverage(base,
bigger=ind,
base_id="id",
bigger_id="POA_CODE_2016")
overlapped <- full_overlap %>%
distinct(id) %>%
mutate(dummy=TRUE)
base_renmant <- base  %>%
left_join(overlapped,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
if(nrow(base_renmant)>0){
intersects <- intersections(base_renmant,
bigger=ind,
base_id="id",
bigger_id="POA_CODE_2016",
base_empty_label="SA2_NAME_2016",
bigger_empty_label="POA_NAME_2016"
)
intersected <- intersects %>%
distinct(id) %>%
mutate(dummy=TRUE)
non_matched <- base_renmant %>%
left_join(intersected,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
}else{
intersects <- base %>% filter(is.null(id))
non_matched <- base %>% filter(is.null(id))
}
base <- base %>%
left_join(full_overlap |> distinct(),by="id") %>%
filter(!is.na(POA_CODE_2016))
base <- bind_rows(base,intersects,non_matched) %>%
mutate(id=row_number())
sa1_nbr <- c(sa1_nbr,nrow(base))
st_write_parquet(base,base_file)
rm(base_renmant,ind,intersects,full_overlap,overlapped,intersected,non_matched)
## suburbs ----
ind <- load_geo(nonabs, layer="state_suburb_2016") %>%
filter(STE_NAME_2016==state) %>%
select(-STE_CODE_2016,-STE_NAME_2016)
full_overlap <- full_coverage(base,
bigger=ind,
base_id="id",
bigger_id="SSC_CODE_2016")
overlapped <- full_overlap %>%
distinct(id) %>%
mutate(dummy=TRUE)
base_renmant <- base  %>%
left_join(overlapped,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
if(nrow(base_renmant)>0){
intersects <- intersections(base_renmant,
bigger=ind,
base_id="id",
bigger_id="SSC_CODE_2016",
base_empty_label="SA2_NAME_2016",
bigger_empty_label="SSC_NAME_2016"
)
intersected <- intersects %>%
distinct(id) %>%
mutate(dummy=TRUE)
non_matched <- base_renmant %>%
left_join(intersected,by="id") %>%
filter(is.na(dummy)) %>%
select(-dummy)
}else{
intersects <- base %>% filter(is.null(id))
non_matched <- base %>% filter(is.null(id))
}
base <- base %>%
left_join(full_overlap |> distinct(),by="id") %>%
filter(!is.na(SSC_CODE_2016))
base <- bind_rows(base,intersects,non_matched) %>%
mutate(id=row_number())
sa1_nbr <- c(sa1_nbr,nrow(base))
st_write_parquet(base,base_file)
rm(base_renmant,ind,intersects,full_overlap,overlapped,intersected,non_matched)
base <- base |> st_make_valid()
base <- bind_rows(data_base |> select(-id),
base |> select(-id))
st_write(base,here("data-raw",str_c("2016_",state,".gpkg")))
state       <- "Western Australia"
state_short <- "Wa"
ceds_2018 <- list_divisions(filters=list(StateAb="WA",`2016`=TRUE)) %>% pull(DivisionNm)
poas_state <- c(6000:6797,0872)
data_base <- load_aussiemaps_gpkg("2016_Western.Australia")
b         <-  load_geo(main, layer = "statistical_area_level_1_2016")  |>
filter(STE_NAME_2016==state)
source(here("data-raw","2016","find_missing.R"))
source(here("data-raw","2016","sequence_2016.R"))
base <- bind_rows(data_base |> select(-id),
base |> select(-id))
st_write(base,here("data-raw",str_c("2016_",state,".gpkg")),append = FALSE,delete_dsn = TRUE)
library(tidyverse)
library(sf)
library(fs)
library(arrow)
library(leaflet)
library(aussiemaps)
library(sfarrow)
library(auspol)
library(here)
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
source(here("R","internal.R"))
main        <- here("data-raw","source","asgs2016absstructuresmainstructureandgccsa.gpkg")
nonabs      <- here("data-raw","source","asgs2016nonabsstructures.gpkg")
nonabs2018  <- here("data-raw","source","asgs2016nonabsstructures.gpkg")
indigenous  <- here("data-raw","source","asgs2016absstructuresindigenousstructure.gpkg")
other       <- here("data-raw","source","asgs2016absstructuressignificanturbanareasurbancentresandlocalitiessectionofstate.gpkg")
main_layers       <- rgdal::ogrListLayers(main)
nonabs_layers     <- rgdal::ogrListLayers(nonabs)
indigenous_layers <- rgdal::ogrListLayers(indigenous)
other_layers      <- rgdal::ogrListLayers(other)
files <- dir_ls(here("data-raw"),regexp = "gpkg")
structure <- NULL
files
file <- files[1]
st_read(file)
map
data <- st_read(file)
for(file in files){
data <- st_read(file) |>
mutate(id=str_c(STE_CODE_2016,"-",row_number()))
st_write(data,file,append = FALSE,delete_dsn = TRUE)
struct_i <- data |> st_drop_geometry()
if(is.null(structure)){
structure <- struct_i
}else{
structure <- bind_rows(structure,struct_i)
}
}
rm(data)
file <- files[1]
#structure <- data_base2 |> st_drop_geometry()
cols <- colnames(structure)
cols <- cols[str_detect(cols,"area|id",TRUE)]
cols <- cols[str_detect(cols,"STATE",TRUE)]
missing <- tibble()
for(col_name in cols){
missing_i <- structure |>
select(any_of(col_name),STATE_NAME_2021) |>
rename("col"=col_name) |>
count(col,STATE_NAME_2021) |>
filter(is.na(col))
if(nrow(missing_i)>0){
missing <- bind_rows(missing,
missing_i |> mutate(col=col_name))
}
}
#structure <- data_base2 |> st_drop_geometry()
cols <- colnames(structure)
cols <- cols[str_detect(cols,"area|id",TRUE)]
cols <- cols[str_detect(cols,"STATE",TRUE)]
missing <- tibble()
for(col_name in cols){
missing_i <- structure |>
select(any_of(col_name),STE_NAME_2016) |>
rename("col"=col_name) |>
count(col,STE_NAME_2016) |>
filter(is.na(col))
if(nrow(missing_i)>0){
missing <- bind_rows(missing,
missing_i |> mutate(col=col_name))
}
}
states_to_remediate <- missing |> distinct(STE_NAME_2016) |> pull()
states_to_remediate <- states_to_remediate[str_detect(states_to_remediate,"Other Territories",TRUE)]
states_to_remediate
states_to_remediate <- missing |> distinct(STE_NAME_2016) |> pull()
missing
missing
structure
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
files <- dir_ls(here("data-raw"),regexp = "gpkg")
geo_structure <- NULL
files <- dir_ls(here("data-raw"),regexp = "gpkg")
structure <- NULL
for(file in files){
data <- st_read(file) |>
mutate(id=str_c(STE_CODE_2016,"-",row_number()))
st_write(data,file,append = FALSE,delete_dsn = TRUE)
struct_i <- data |> st_drop_geometry()
if(is.null(structure)){
structure <- struct_i
}else{
structure <- bind_rows(structure,struct_i)
}
}
rm(data)
geo_structure  <- structure
rm(data,struct_i,structure)
geo_structure <- geo_structure |>
relocate(id,.before=1)
save_zip_parquet(geo_structure,"2016_structure",here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
for(geo_col in geo_cols){
message(geo_col)
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
structure <- NULL
for(file in files){
data <- st_read(file) |>
mutate(id=str_c(STE_CODE_2016,"-",row_number()))
data$area <- st_area(data)
st_write(data,file,append = FALSE,delete_dsn = TRUE)
struct_i <- data |> st_drop_geometry()
if(is.null(structure)){
structure <- struct_i
}else{
structure <- bind_rows(structure,struct_i)
}
}
geo_structure  <- structure
rm(data,struct_i,structure)
#save structure, create proportions ----
geo_structure <- geo_structure |>
relocate(id,.before=1)
save_zip_parquet(geo_structure,"2016_structure",here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
for(geo_col in geo_cols){
message(geo_col)
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
library(sf)
library(here)
source(here("data-raw","aux_save.R"))
library(fs)
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
source(here("R","internal.R"))
library(sf)
library(here)
library(fs)
source(here("data-raw","aux_save.R"))
files <- dir_ls(here("R","data-raw"),regexp = "gpkg$")
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
nsw <- files[str_detect(files,"New South Wales")]
splits <- 4
rep(1,splits)/splits
1:splits
1:splits/splits
delimiters <- (1:splits/splits)*nrow(nsw)
delimiters
(1:splits/splits)*nrow(nsw)
nrow(nsw)
nsw_map <- st_read(nsw)
splits <- 4
delimiters <- (1:splits/splits) nrow(nsw)
delimiters <- (1:splits/splits)* nrow(nsw)
delimiters
delimiters <- (1:splits/splits)* nrow(nsw_map)
delimiters
delimiters <- floor((1:splits/splits)* nrow(nsw_map))
delimiters
nrow(nsw_map)
delimites  <- c(1,delimiters)
delimiters  <- c(1,delimiters)
nsw_map[delimiters[i]:(delimiters[i+1]),]
i<1-
1d
i<-1
nsw_map[delimiters[i]:(delimiters[i+1]),]
nsw <- files[str_detect(files,"New South Wales")]
nsw_map <- st_read(nsw)
splits <- 4
delimiters <- floor((1:splits/splits)* nrow(nsw_map))
delimiters  <- c(1,delimiters)
for(i in 1:splits){
partial <- nsw_map[delimiters[i]:(delimiters[i+1]),]
st_write(partial(here("data-raw",glue::glue("2021_New.South Wales.{i}.gpkg"))))
}
for(i in 1:splits){
partial <- nsw_map[delimiters[i]:(delimiters[i+1]),]
st_write(partial,(here("data-raw",glue::glue("2021_New.South Wales.{i}.gpkg"))))
}
files <- files[str_detect(files,"New South Wales",TRUE)]
for(file in files){
fs::file_move(file,str_replace(file," ","\\."))
}
for(file in files){
fs::file_move(file,str_replace_all(file," ","\\."))
}
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
files <- files[str_detect(files,"Wales",TRUE)]
for(file in files){
fs::file_move(file,str_replace_all(file," ","\\."))
}
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
files <- files[str_detect(files,"New South Wales".TRUE)]
files <- files[str_detect(files,"New South Wales",TRUE)]
files
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
nsw <- files[str_detect(files,"New South Wales")]
nsw_map <- st_read(nsw)
splits <- 5
delimiters <- floor((1:splits/splits)* nrow(nsw_map))
delimiters  <- c(1,delimiters)
for(i in 1:splits){
partial <- nsw_map[delimiters[i]:(delimiters[i+1]),]
st_write(partial,(here("data-raw",glue::glue("2021_New.South Wales.{i}.gpkg"))))
}
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
files <- files[str_detect(files,"New South Wales",TRUE)]
files
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
files <- files[str_detect(files,"New South Wales",TRUE)]
for(file in files){
save_zip_gpkg(file,here("data-raw"),here("data-raw","processed"))
}
files
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
files <- files[str_detect(files,"Wales.gpkg",TRUE)]
files
for(file in files){
fs::file_move(file,str_replace_all(file," ","\\."))
}
files <- dir_ls(here("data-raw"),regexp = "gpkg$")
files <- files[str_detect(files,"New South Wales",TRUE)]
files
files <- files[str_detect(files,"Wales")]
files
for(file in files){
save_zip_gpkg(file,here("data-raw"),here("data-raw","processed"))
}
base|>
leaflet() |>
addTiles() |>
addPolygons(fillColor = "red") # |>
nsw_map|>
leaflet() |>
addTiles() |>
addPolygons(fillColor = "red") # |>
library(piggyback)
library(here)
library(fs)
library(tidyverse)
files_dir      <- here("data-raw","processed")
repo           <- "carlosyanez/aussiemaps"
version       <- "data"
files <- tibble(path=dir_ls(files_dir),
file=str_remove(path,str_c(files_dir,"/"))) |>
mutate(file_mod=str_replace_all(file," ","."))
set.seed(123)
files <- slice_sample(files,prop=1)
#create new release
#pb_new_release(repo,version)
group_size <- round(nrow(files)/6,0)
steps <- seq(1,nrow(files),by=round(nrow(files)/group_size,0))
# upload catalogue items ---
today <- piggyback::pb_list(repo)
today <- today |> filter(str_detect(file_name,"2021")) |>
filter(lubridate::date(timestamp)==lubridate::today())
files <- files |>
filter(!(file_mod %in% today$file_name))
for(file in files$path){
message(file)
#files_list <- files[steps[i-1]:steps[i],]
pb_upload(file,repo,version)
#tryCatch(pb_upload(file=file,repo,version),
#         error=function(e){print(e)})
message("next")
Sys.sleep(60)
}
