#
#   names(join_key) <- aggregation[i]
#
#   data_sf <- data_sf |>
#              left_join(areas_prop[[i]], by=join_key) |>
#               filter(if_any(c("prop_i"), ~  !is.na(.x)))
#
#   if("prop" %in% colnames(data_sf)){
#
#   }else{
#     data_sf <- data_sf |>
#                rename()
#
#   }
#   }
# exists_name <- any(colnames(data_sf)==str_replace(aggregation,"_(.*?)CODE","_NAME"))
# #if(exists_name){
#   agg_label <- colnames(data_sf)[str_detect(colnames(data_sf),
#                                           str_replace(aggregation,"_(.*?)CODE","_NAME"))]
#
#   data_sf$label <- data_sf |>
#                   select(any_of(as.vector(agg_label))) |>
#                   st_drop_geometry() |>
#                    pull()
#
#   data_sf <- data_sf |>
#               mutate(label=if_else(.data$prop==1,.data$label,str_c(.data$label, " (partial)")))
#
# }
#simplify
tryCatch(data_sf <- suppressMessages(suppressWarnings(
data_sf |>
ms_simplify(keep=simplification_factor))),
error = function(e) e)
}
data_sf <- NULL
message("collecting")
for(repo_i in required_states){
message(repo_i)
data_i <- suppressMessages(suppressWarnings(load_aussiemaps_gpkg(repo_i,filter_table)))
col_names <- colnames(data_i)
data_i <- data_i |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character))
data_sf <- bind_rows(data_sf,data_i)
}
d2 <- data_sf
external_territories
state_col
data_sf |> filter(if_any(as.vector(state_col), ~ str_detect(.x,"Other"),TRUE))
data_sf |> filter(if_any(as.vector(state_col), ~ str_detect(.x,"Other",TRUE)))
data_sf           <- data_sf |> filter(if_any(as.vector(state_col), ~ str_detect(.x,"Other",TRUE)))
data_sf |> filter(if_any(as.vector(state_col), ~ str_detect(.x,"Other")))
required_states
View(data_sf)
unique(data_sf$STATE_NAME_2021)
unique(data_sf$STATE_CODE_2021)
data_i
required_states
repo_i <- required_states[2]
data_i <- suppressMessages(suppressWarnings(load_aussiemaps_gpkg(repo_i,filter_table)))
data_i
filter_table
unique(filter_table$STATE_NAME_2021)
View(data_sf_external)
data_i |> filter(STATE_NAME_2021=="New South Wales")
filter_table |> filter(STATE_NAME_2021=="New South Wales")
library(tidyverse)
library(sf)
library(arrow)
library(fs)
library(here)
library(zip)
library(piggyback)
library(rgdal)
library(aussiemaps)
source(here("R","internal.R"))
source(here("R","cache_management.R"))
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
cache_dir  <- find_maps_cache()
years <- c(2006,2011,2016,2021)
file_regex <- str_c("[0-9]{4}_[A-Z]{1}")
repo       <- read_parquet(path(cache_dir,"repo.parquet")) |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))                                   |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
changes <- rep(FALSE,length(years))
years
i <- 2006
year <- years[i]
year
i<-1
year <- years[i]
year
repo_year <- repo[str_detect(repo,as.character(year))]
repo_year
geo_structure <- NULL
changes_i <- FALSE
repo_year
map <- repo_year[1]
map
if(file_exists("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")){
fs::file_delete("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")}
map_i <- load_aussiemaps_gpkg(map)
map_i
map_i_id_1 <- map_i |> st_drop_geometry() |> head(1) |> pull(id)
map_i_id_1
str_detect(map_i_id_1,"-",TRUE)
changes_i <- TRUE
state_col <- colnames(map_i)[str_detect(colnames(map_i),"STATE|STE")]
state_col
state_col <- state_col[str_detect(state_col,"CODE")]
state_col_pos <-which(colnames(map_i)==state_col)
state_code <- map_i[1,state_col_pos] |> st_drop_geometry() |> pull()
map_i <- map_i |>
mutate(id=str_c(state_code,"-",row_number())) |>
mutate(Year=year) |>
mutate(across(contains("CODE"),as.character))
map_i
file_gpkg <- str_c(map,".gpkg")
file_gpkg
st_write(map_i,here("data-raw",file_gpkg),layer=map)
save_zip_gpkg(here("data-raw",file_gpkg),
here("data-raw"),
here("data-raw","processed"))
map_i$area <- st_area(map_i)
map_i
map_i <- map_i %>% st_drop_geometry()
geo_structure <- bind_rows(geo_structure,map_i)
geo_structure
changes_i
if(changes[i]){
geo_structure <-  geo_structure |>
relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
changes[i]
changes_i
if(changes_i){
changes[i] <- TRUE
}
(changes[i]
)
if(changes[i]){
geo_structure <-  geo_structure |>
relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
changes[i]
if(any(changes[i])){
geo_structure <-  geo_structure |>
relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
any(changes[i])
library(tidyverse)
library(sf)
library(arrow)
library(fs)
library(here)
library(zip)
library(piggyback)
library(rgdal)
library(aussiemaps)
source(here("R","internal.R"))
source(here("R","cache_management.R"))
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
cache_dir  <- find_maps_cache()
years <- c(2006,2011,2016,2021)
file_regex <- str_c("[0-9]{4}_[A-Z]{1}")
repo       <- read_parquet(path(cache_dir,"repo.parquet")) |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))                                   |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
changes <- rep(FALSE,length(years))
for(i in 1:length(years)){
year <- years[i]
repo_year <- repo[str_detect(repo,as.character(year))]
geo_structure <- NULL
changes_i <- FALSE
for(map in repo_year){
if(file_exists("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")){
fs::file_delete("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")}
map_i <- load_aussiemaps_gpkg(map)
#map_i <- st_read(path(cache_dir,str_c(map,".gpkg")))
map_i_id_1 <- map_i |> st_drop_geometry() |> head(1) |> pull(id)
if(str_detect(as.character(map_i_id_1),"-",TRUE)){
changes_i <- TRUE
state_col <- colnames(map_i)[str_detect(colnames(map_i),"STATE|STE")]
state_col <- state_col[str_detect(state_col,"CODE")]
state_col_pos <-which(colnames(map_i)==state_col)
state_code <- map_i[1,state_col_pos] |> st_drop_geometry() |> pull()
map_i <- map_i |>
mutate(id=str_c(state_code,"-",row_number())) |>
mutate(Year=year) |>
mutate(across(contains("CODE"),as.character))
file_gpkg <- str_c(map,".gpkg")
st_write(map_i,here("data-raw",file_gpkg),layer=map)
save_zip_gpkg(here("data-raw",file_gpkg),
here("data-raw"),
here("data-raw","processed"))
}
map_i$area <- st_area(map_i)
map_i <- map_i %>% st_drop_geometry()
geo_structure <- bind_rows(geo_structure,map_i)
if(changes_i){
changes[i] <- TRUE
}
}
if(any(changes[i])){
geo_structure <-  geo_structure |>
relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
}
library(tidyverse)
library(sf)
library(arrow)
library(fs)
library(here)
library(zip)
library(piggyback)
library(rgdal)
library(aussiemaps)
source(here("R","internal.R"))
source(here("R","cache_management.R"))
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
cache_dir  <- find_maps_cache()
years <- c(2006,2011,2016,2021)
file_regex <- str_c("[0-9]{4}_[A-Z]{1}")
repo       <- read_parquet(path(cache_dir,"repo.parquet")) |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))                                   |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
changes <- rep(FALSE,length(years))
for(i in 1:length(years)){
year <- years[i]
repo_year <- repo[str_detect(repo,as.character(year))]
geo_structure <- NULL
changes_i <- FALSE
for(map in repo_year){
if(file_exists("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")){
fs::file_delete("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")}
map_i <- load_aussiemaps_gpkg(map)
#map_i <- st_read(path(cache_dir,str_c(map,".gpkg")))
map_i_id_1 <- map_i |> st_drop_geometry() |> head(1) |> pull(id)
if(str_detect(as.character(map_i_id_1),"-",TRUE)){
changes_i <- TRUE
state_col <- colnames(map_i)[str_detect(colnames(map_i),"STATE|STE")]
state_col <- state_col[str_detect(state_col,"CODE")]
state_col_pos <-which(colnames(map_i)==state_col)
state_code <- map_i[1,state_col_pos] |> st_drop_geometry() |> pull()
map_i <- map_i |>
mutate(id=str_c(state_code,"-",row_number())) |>
mutate(Year=year) |>
mutate(across(contains("CODE"),as.character))
file_gpkg <- str_c(map,".gpkg")
st_write(map_i,here("data-raw",file_gpkg),layer=map)
save_zip_gpkg(here("data-raw",file_gpkg),
here("data-raw"),
here("data-raw","processed"))
}
map_i$area <- st_area(map_i)
map_i <- map_i %>% st_drop_geometry()
geo_structure <- bind_rows(geo_structure,map_i)
if(changes_i){
changes[i] <- TRUE
}
}
if(any(changes[i])){
geo_structure <-  geo_structure |>
relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
}
library(tidyverse)
library(sf)
library(arrow)
library(fs)
library(here)
library(zip)
library(piggyback)
library(rgdal)
library(aussiemaps)
source(here("R","internal.R"))
source(here("R","cache_management.R"))
source(here("data-raw","aux_save.R"))
source(here("data-raw","functions.R"))
cache_dir  <- find_maps_cache()
years <- c(2006,2011,2016,2021)
file_regex <- str_c("[0-9]{4}_[A-Z]{1}")
repo       <- read_parquet(path(cache_dir,"repo.parquet")) |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))                                   |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
changes <- rep(FALSE,length(years))
for(i in 1:length(years)){
year <- years[i]
repo_year <- repo[str_detect(repo,as.character(year))]
geo_structure <- NULL
changes_i <- FALSE
for(map in repo_year){
if(file_exists("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")){
fs::file_delete("C:/Users/carlo/OneDrive/Documents/.aussiemaps_cache/temp.gpkg")}
map_i <- load_aussiemaps_gpkg(map)
#map_i <- st_read(path(cache_dir,str_c(map,".gpkg")))
map_i_id_1 <- map_i |> st_drop_geometry() |> head(1) |> pull(id)
if(str_detect(as.character(map_i_id_1),"-",TRUE)){
changes_i <- TRUE
state_col <- colnames(map_i)[str_detect(colnames(map_i),"STATE|STE")]
state_col <- state_col[str_detect(state_col,"CODE")]
state_col_pos <-which(colnames(map_i)==state_col)
state_code <- map_i[1,state_col_pos] |> st_drop_geometry() |> pull()
map_i <- map_i |>
mutate(id=str_c(state_code,"-",row_number())) |>
mutate(Year=year) |>
mutate(across(contains("CODE"),as.character))
file_gpkg <- str_c(map,".gpkg")
st_write(map_i,here("data-raw",file_gpkg),layer=map)
save_zip_gpkg(here("data-raw",file_gpkg),
here("data-raw"),
here("data-raw","processed"))
}
map_i$area <- st_area(map_i)
map_i <- map_i %>% st_drop_geometry()
geo_structure <- bind_rows(geo_structure,map_i)
if(changes_i){
changes[i] <- TRUE
}
}
if(any(changes[i])){
geo_structure <-  geo_structure |>
relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
}
for(i in 1:length(years)){
if(changes[i]){
year <- years[i]
geo_structure <- load_aussiemaps_parquet(str_c(year,"_structure"))
geo_cols <- geo_structure$schema$names
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
select(any_of(c(geo_col,"id","area"))) %>%
collect() %>%
filter(!is.na(area)) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
print(str_c(which(geo_cols==geo_col)," out of", length(geo_cols),": ",geo_col)
)
}
}
}
library(piggyback)
library(here)
library(fs)
library(tidyverse)
files_dir      <- here("data-raw","processed")
repo           <- "carlosyanez/aussiemaps"
version       <- "data"
files_list <- tibble(file=dir_ls(files_dir)) ,
files_list <- tibble(file=dir_ls(files_dir))
# upload catalogue items ---
pb_upload(file=files_list$file,repo,version)
