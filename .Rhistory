relocate(id,.before=1) |>
select(-matches("\\."))
save_zip_parquet(geo_structure,str_c(year,"_structure"),here("data-raw","processed"))
geo_cols <- colnames(geo_structure)
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
attributes <- geo_structure[1,] %>%
select(-area,-Year,-any_of(c("AREA_ALBERS_SQKM"))) %>%
pivot_longer(-id,names_to="attributes",values_to = "value") %>%
select(attributes)
save_zip_parquet(attributes,str_c(year,"_attributes"),here("data-raw","processed"))
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
filter(!is.na(area)) %>%
select(any_of(c(geo_col,"id","area"))) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
}
}
}
for(i in 1:length(years)){
if(changes[i]){
year <- years[i]
geo_structure <- load_aussiemaps_parquet(str_c(year,"_structure"))
geo_cols <- geo_structure$schema$names
geo_cols <- geo_cols[str_detect(geo_cols,"CODE")]
for(geo_col in geo_cols){
struct_i <- geo_structure %>%
select(any_of(c(geo_col,"id","area"))) %>%
collect() %>%
filter(!is.na(area)) %>%
rename("col"=geo_col) %>%
group_by(col) %>%
mutate(sum_area = sum(area)) %>%
ungroup() %>%
mutate(prop=if_else(sum_area>units::set_units(0,m^2),
as.numeric(area/sum_area),
0)) %>%
rename(geo_col="col")
save_zip_parquet(struct_i,geo_col,here("data-raw","processed"))
print(str_c(which(geo_cols==geo_col)," out of", length(geo_cols),": ",geo_col)
)
}
}
}
library(piggyback)
library(here)
library(fs)
library(tidyverse)
files_dir      <- here("data-raw","processed")
repo           <- "carlosyanez/aussiemaps"
version       <- "data"
files_list <- tibble(file=dir_ls(files_dir)) ,
files_list <- tibble(file=dir_ls(files_dir))
# upload catalogue items ---
pb_upload(file=files_list$file,repo,version)
#############################################################
### Internal functions ####
#############################################################
## Based on https://github.com/walkerke/aussiemaps/blob/master/R/helpers.R , released under MIT licence.
#' Helper function to download data from github release
#'
#' @importFrom  piggyback pb_download_url
#' @importFrom  arrow open_dataset
#' @importFrom  stringr str_remove str_c str_detect
#' @importFrom utils download.file
#' @importFrom  zip unzip
#' @importFrom fs path
#' @param aussiemaps_file name of the file to download.
#' @return data frame or parquet binding
#' @noRd
load_aussiemaps <- function(aussiemaps_file) {
cache_files <- data_maps_info()$path
cache_dir   <- find_maps_cache()
file_detect <- any(str_detect(cache_files,aussiemaps_file))
if(!file_detect) {
filename <- str_c(aussiemaps_file,".zip")
url  <- pb_download_url(filename,
repo = "carlosyanez/aussiemaps",
tag = "data")
file_path <- path(cache_dir,filename)
download.file(url,path(cache_dir,filename))
unzip(file_path,exdir = cache_dir)
file.remove(file_path)
}
cache_files <- data_maps_info()$path
file_path <- cache_files[str_detect(cache_files,aussiemaps_file)]
return(file_path)
}
#' Helper function to import gpkg data
#'
#' @importFrom arrow open_dataset
#' @param aussiemaps_file name of the file to download.
#' @return sf parquet binding
#' @noRd
load_aussiemaps_parquet <- function(aussiemaps_file){
file_name <- load_aussiemaps(aussiemaps_file)
data <- open_dataset(file_name,format="parquet")
return(data)
}
#' Helper function to import gpkg data
#'
#' @importFrom fs path file_copy
#' @importFrom sf st_write st_read st_layers
#' @importFrom stringr str_c str_remove_all str_squish
#' @importFrom dplyr mutate across
#' @importFrom tidyselect where
#' @param aussiemaps_file name of the file to download.
#' @param filter_ids data frame with ids to filter (id column)
#' @return sf data frame
#' @noRd
load_aussiemaps_gpkg <- function(aussiemaps_file,filter_ids=NULL){
file_name <- load_aussiemaps(aussiemaps_file)
temp_gpkg <- path(find_maps_cache(),"temp.gpkg")
file_copy(file_name,temp_gpkg,overwrite=TRUE)
data_layer <- st_layers(file_name)$name[1]
if(!is.null(filter_ids)){
st_write(filter_ids,temp_gpkg,layer="id",append=TRUE)
query_text <- str_c("SELECT * FROM '",data_layer,"' WHERE id IN (SELECT id FROM id)")
}else{
query_text <- str_c("SELECT * FROM '",data_layer,"'")
}
data <- st_read(temp_gpkg,query=query_text) |>
mutate(across(where(is.character), ~ str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]")))
return(data)
}
#' Update list of files in repo
#' @importFrom piggyback pb_list
#' @importFrom arrow write_parquet
#' @importFrom fs path file_exists file_info
#' @importFrom lubridate now interval days
#' @noRd
get_repo_files <- function(){
cache_dir <-  find_maps_cache()
local_repo <- path(cache_dir,"repo.parquet")
if(file_exists(local_repo)){
creation <- file_info(local_repo)$birth_time
now <- now()
age <- interval(creation,now)/days(1)
if(age>1){
repo      <- pb_list("carlosyanez/aussiemaps")
write_parquet(repo,path(cache_dir,"repo.parquet"))
}else{
repo <- read_parquet(path(cache_dir,"repo.parquet"))
}
}else{
repo      <- pb_list("carlosyanez/aussiemaps")
write_parquet(repo,path(cache_dir,"repo.parquet"))
}
return(repo)
}
library(aussiemaps)
filter_table=list_structure(2021,list(STATE_NAME_2021="Western Australia"))
year=2021
aggregation = "SA4_CODE_2021"
simplification_factor =1
use_cache = TRUE
cache_intermediates=TRUE
smoothing_threshold=4
simplification_factor=1
data <- get_map_internal(filter_table,
year,
aggregation,
simplification_factor,
smoothing_threshold,
cache_intermediates)
repo_base      <- get_repo_files() |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))
repo      <- repo_base |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
state_col <- colnames(filter_table)[str_detect(colnames(filter_table),"STATE|STE")]
library(tidyverse)
repo_base      <- get_repo_files() |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))
library(fs)
library(sf)
repo_base      <- get_repo_files() |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))
file_regex <- str_c(year,"_[A-Z]{1}")
repo      <- repo_base |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
repo_base      <- get_repo_files() |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))
library(arrow)
repo_base      <- get_repo_files() |>
mutate(across(c("file_name"), ~ str_remove_all(.x,"\\.zip"))) |>
select(any_of("file_name"))
repo      <- repo_base |>
filter(if_any(c("file_name"), ~ str_detect(.x,file_regex)))   |>
pull()
state_col <- colnames(filter_table)[str_detect(colnames(filter_table),"STATE|STE")]
state_col <- state_col[str_detect(state_col,"NAME")]
required_states <- filter_table |>
select(all_of(c(state_col))) |>
distinct() |>
mutate(across(all_of(as.vector(state_col)), ~ str_replace_all(.x," ","\\."))) |>
mutate(across(all_of(as.vector(state_col)), ~ str_c(year,"_",.x))) |>
filter(if_any(all_of(as.vector(state_col)), ~ .x %in% repo))           |>
pull()
cols_to_keep <-filter_table |>
mutate(across(everything(), as.character)) |>
select(-any_of(c("id","area","Year"))) |>
pivot_longer(-any_of(aggregation),values_to = "value",names_to = "geo_unit") |>
distinct() |>
group_by(across(all_of(c(aggregation,"geo_unit")))) |>
summarise(n=n(),.groups="drop") |>
group_by(across(all_of(c("geo_unit")))) |>
summarise(n=mean(n),.groups="drop") |>
filter(if_any(c("n"), ~ .x==1)) |>
select(any_of("geo_unit")) |>
distinct() |>
pull()
cols_to_keep <- c(cols_to_keep,"Year")
cols_to_keep <- cols_to_keep[str_detect(cols_to_keep,"AREA_ALBERS_SQKM",TRUE)]
cols_to_merge <- colnames(filter_table)
cols_to_merge <- cols_to_merge[!(cols_to_merge %in% c(cols_to_keep,aggregation,"id","area"))]
cols_to_merge <- cols_to_merge[str_detect(cols_to_merge,"AREA_ALBERS_SQKM",TRUE)]
data_sf <- NULL
repo_i <- required_states
data_i <- suppressMessages(suppressWarnings(load_aussiemaps_gpkg(repo_i,filter_table)))
data_i
data_i <- data_i |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character)) |>
group_by(across(c(aggregation,cols_to_keep))) |>
st_make_valid() |>
st_buffer(0) |>
summarise(.groups="drop") |>
st_make_valid()
data_i <- data_i |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character)) |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
aggregation
cols_to_keep
#distinct values
distinct_combos <- data_i |> st_drop_geometry() |>
distinct(any_of(c(aggregation,cols_to_keep)))
#distinct values
distinct_combos <- data_i |> st_drop_geometry() |>
select(any_of(c(aggregation,cols_to_keep))) |>
distinct()
distinct_combos
j<-1
data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(flag) |> select(any_of(c(flag)))
i<-1
data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(flag) |> select(any_of(c(flag)))
#distinct values
distinct_combos <- data_i |> st_drop_geometry() |>
select(any_of(c(aggregation,cols_to_keep))) |>
distinct() |>
mutate(flag=TRUE)
distinct_combos
data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(flag) |> select(any_of(c(flag)))
distinct_combos[i,]
#distinct values
distinct_combos <- data_i |> st_drop_geometry() |>
select(any_of(c(aggregation,cols_to_keep))) |>
distinct() |>
mutate(filter_flag=TRUE)
data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag)
data_j <- data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(any_of(c(flag))) |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character)) |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
data_j <- data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c(filter_flag))) |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character)) |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag)
data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c("filter_flag")))
data_j <- data_i |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c("filter_flag"))) |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character)) |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
data_base <- suppressMessages(suppressWarnings(load_aussiemaps_gpkg(repo_i,filter_table)))
data_base <- data_base |>
mutate(across(where(is.character), ~str_squish(.x))) |>
mutate(across(where(is.character), ~ str_remove_all(.x, "[^A-z|0-9|[:punct:]|\\s]"))) |>
mutate(across(any_of(c("id")), as.character)) |>
st_make_valid() |>
st_buffer(0)
col_names <- colnames(data_base[1,])
col_names
#distinct values
distinct_combos <- data_base |> st_drop_geometry() |>
select(any_of(c(aggregation,cols_to_keep))) |>
distinct() |>
mutate(filter_flag=TRUE)
#distinct values
distinct_combos <- data_base |> st_drop_geometry() |>
select(any_of(c(aggregation,cols_to_keep))) |>
distinct() |>
mutate(filter_flag=TRUE)
data_i <- tibble()
for(j in 1:nrow(distinct_combos)){
data_j <- data_base |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c("filter_flag"))) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
data_i <- bind_rows(data_i,data_j)
}
data_j
data_i <- NULL
for(j in 1:nrow(distinct_combos)){
data_j <- data_base |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c("filter_flag"))) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
if(is.null(data_i)){
data_i <- data_j
}else{
data_i <- bind_rows(data_i,data_j)
}
}
for(j in 1:nrow(distinct_combos)){
message(str_c("merging ",i," out of ",nrow(distinct_combos)))
data_j <- data_base |>
left_join(distinct_combos[i,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c("filter_flag"))) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
if(is.null(data_i)){
data_i <- data_j
}else{
data_i <- bind_rows(data_i,data_j)
}
}
data_i <- NULL
for(j in 1:nrow(distinct_combos)){
message(str_c("merging ",j," out of ",nrow(distinct_combos)))
data_j <- data_base |>
left_join(distinct_combos[j,],by=c(aggregation,cols_to_keep)) |>
filter(filter_flag) |>
select(-any_of(c("filter_flag"))) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid()
if(is.null(data_i)){
data_i <- data_j
}else{
data_i <- bind_rows(data_i,data_j)
}
}
aggregation <- as.vector(aggregation)
aggregation
length(aggregation)
aggregation_prefix <- str_extract(aggregation[i],"^[^_]*")
aggregation_prefix
aggregation_suffix <- str_extract(aggregation[i],"[0-9]{4}")
aggregation_suffix
aggregation[i]  <- repo_base |>
filter(if_any(c("file_name"), ~ str_detect(.x,aggregation_prefix))) |>
filter(if_any(c("file_name"), ~ str_detect(.x,as.character(aggregation_suffix)))) |>
filter(if_any(c("file_name"), ~ str_detect(.x,"CODE"))) |>
head(1) |>
pull()
aggregation
repo_base
#new aggregated sum
areas_prop <- list()
aggregation
areas_prop[[i]] <- load_aussiemaps_parquet(aggregation[i]) |>
filter(if_any(c("id"), ~ .x %in% filter_table$id)) |>
collect() |>
group_by(across(c("geo_col")))   |>
summarise(across(any_of("prop"), ~ sum(.x)),.groups="drop")
areas_prop
data_sf <- data_i
data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid() |>
fill_holes(set_units(smoothing_threshold,"km^2")
)
library(smoothr)
data_sf <- suppressMessages(suppressWarnings(data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid() |>
fill_holes(set_units(smoothing_threshold,"km^2"))
))
library(units)
data_sf <- suppressMessages(suppressWarnings(data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid() |>
fill_holes(set_units(smoothing_threshold,"km^2"))
))
data_sf <- suppressMessages(suppressWarnings(data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid()
))
data_sf
View(data_j)
data_sf |> select(SA4_NAME_2021)
st_is_empty
st_is_empty(data_sf)
data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid()
filter(st_is_empty())
data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid()   |>
filter(st_is_empty())
data_sf <- suppressMessages(suppressWarnings(data_sf |>
st_make_valid() |>
st_buffer(0) |>
group_by(across(c(aggregation,cols_to_keep))) |>
summarise(.groups="drop") |>
st_make_valid() |>
st_union(by_feature = TRUE) |>
st_make_valid()))
data_sf
data_sf$empty <- st_is_empty(data_sf)
data_sf |>
filter(!empty)
data_sf |>
filter(!empty)|>
fill_holes(set_units(smoothing_threshold,"km^2"))
